{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "continent-suite",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from copy import copy\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import math \n",
    "import numpy as np\n",
    "import random\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "from scipy.ndimage.measurements import label\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "floral-awareness",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrive_data(noncar_size = 20):\n",
    "    \n",
    "    sup_path = './benchmark_velocity_supp/'\n",
    "    folder_sup = os.listdir(sup_path)\n",
    "    with open(os.path.join(sup_path,'annotation.json'),'r') as f:\n",
    "        gt = json.load(f)\n",
    "    f.close()\n",
    "    imgs = []\n",
    "    cars = []\n",
    "    nocars = []\n",
    "    #img_count=0\n",
    "    for i in tqdm(gt):\n",
    "        subset = i\n",
    "        img = cv2.imread(os.path.join(sup_path ,subset['file_name']))\n",
    "        imgs.append(img)\n",
    "        aim = subset['bbox']\n",
    "        coordinates = []\n",
    "        for j in aim:\n",
    "            left = int(j['left'])\n",
    "            top = int(j['top'])\n",
    "            bottom = int(j['bottom'])\n",
    "            right = int(j['right'])\n",
    "            car_img = img[top:bottom,left:right]\n",
    "            if car_img.size:\n",
    "                coordinates.append([(top - 32,bottom + 32),(left - 32,right + 32)])\n",
    "                img_resized = cv2.resize(car_img,(64, 64),interpolation = cv2.INTER_CUBIC)\n",
    "                cars.append(img_resized)\n",
    "        count = 0\n",
    "        while(count<noncar_size):\n",
    "            h = random.randint(270,685) # prevent out of range\n",
    "            v = random.randint(32,1230)\n",
    "            for c in coordinates:\n",
    "                if h in range(c[0][0],c[0][1]) and v in range(c[1][0],c[1][1]):\n",
    "                    break\n",
    "                else:\n",
    "                    nocars.append(img[h-32:h+32,v-32:v+32])\n",
    "                    #imgname = \"./non-vehicles/noncars/\"+\"noncar_img_\"+str(img_count)+\".jpg\"\n",
    "                    #cv2.imwrite(imgname, img[h-32:h+32,v-32:v+32])\n",
    "                    count += 1\n",
    "                    #img_count += 1\n",
    "\n",
    "# Read from processed images\n",
    "#     nocars=[]\n",
    "#     nocars_path = \"./non-vehicles/noncars/\"\n",
    "#     for _, _, imgs in tqdm(os.walk(nocars_path)):\n",
    "#         for img_name in imgs:\n",
    "#             if img_name != '.DS_Store':\n",
    "#                 img_path = nocars_path + img_name\n",
    "#                 file = cv2.imread(img_path)\n",
    "#                 nocars.append(file)\n",
    "    \n",
    "    return imgs, cars, nocars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acting-archives",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrive_features(imgs, hist_bins = 32, spatial_size = (16,16), hog_orientations = 9, hog_pixels_per_cell = (8, 8), hog_cells_per_block = (1, 1)):\n",
    "    img_features = []\n",
    "    \n",
    "    for i in tqdm(imgs):\n",
    "        img = cv2.cvtColor(i,cv2.COLOR_BGR2YCrCb)\n",
    "        # extract color hist features\n",
    "        channel1 = np.histogram(img[:, :, 0],bins=hist_bins)\n",
    "        channel2 = np.histogram(img[:, :, 1],bins=hist_bins)\n",
    "        channel3 = np.histogram(img[:, :, 2],bins=hist_bins)\n",
    "        hist_feature = np.concatenate((channel1[0], channel2[0], channel3[0]))\n",
    "        \n",
    "        # extract spatial features\n",
    "        spatial_features = cv2.resize(img,spatial_size).ravel()\n",
    "        \n",
    "        # extract hog features\n",
    "        hog_feature = hog(img, orientations=hog_orientations, pixels_per_cell=hog_pixels_per_cell,\n",
    "                          cells_per_block=hog_cells_per_block, visualize=False,feature_vector=True)\n",
    "        \n",
    "        img_features.append(np.concatenate((hist_feature, spatial_features, hog_feature)))\n",
    "    return img_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "numerical-imagination",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(car_features,nocars_features, random_state=0):\n",
    "    #print(type(car_features),len(car_features))\n",
    "    #print(type(nocars_features),len(nocars_features))\n",
    "    x = np.vstack((car_features, nocars_features))\n",
    "    #print(type(x),x.shape)\n",
    "    y = np.hstack((np.ones(len(car_features)), np.zeros(len(nocars_features))))\n",
    "    scaler = RobustScaler().fit(x)\n",
    "    x = scaler.transform(x)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "    svc = LinearSVC()\n",
    "    svc.fit(x_train, y_train)\n",
    "    predict = svc.predict(x_test)\n",
    "    accuracy = metrics.accuracy_score(y_test,predict)\n",
    "    recall = metrics.recall_score(y_test,predict,average='macro')\n",
    "    print(f\"Accuracy:{accuracy:0.3f}\\t Recall:{recall:0.3f}\")\n",
    "    print(\"SVM\")\n",
    "    print(metrics.confusion_matrix(y_test,predict))\n",
    "    return svc,scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "handed-luxury",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slide_window(img, window_size=(64, 64), overlap=0.5):\n",
    "    step = window_size[0] * (1 - overlap)\n",
    "    number_of_window_x = int((img.shape[1] - window_size[0] * overlap) / step)\n",
    "    number_of_window_y = int((img.shape[0] - window_size[1] * overlap) / step)\n",
    "    windows = []\n",
    "    for y in range(number_of_window_y):\n",
    "        for x in range(number_of_window_x):\n",
    "            startx = int(x * step)\n",
    "            starty = int(y * step) + 270\n",
    "            # change the window size based on distance \n",
    "            if starty+window_size[0]*2.5 <= img.shape[0]:\n",
    "                if starty < 400:\n",
    "                    endy = starty + window_size[1]\n",
    "                    endx = startx + window_size[0]\n",
    "                    windows.append(((startx, starty), (endx, endy)))\n",
    "                elif starty >= 400 and starty < 432:\n",
    "                    endy = int(starty + window_size[1]*1.5)\n",
    "                    endx = int(startx + window_size[0]*1.5)\n",
    "                    windows.append(((startx, starty), (endx, endy)))\n",
    "                elif starty >= 432 and starty < 448:\n",
    "                    endy = starty + window_size[1]*2\n",
    "                    endx = startx + window_size[0]*2\n",
    "                    windows.append(((startx, starty), (endx, endy)))\n",
    "                elif starty >= 448 and starty < 500:\n",
    "                    endy = int(starty + window_size[1]*2.5)\n",
    "                    endx = int(startx + window_size[0]*2.5)\n",
    "                    windows.append(((startx, starty), (endx, endy)))\n",
    "            \n",
    "    return windows\n",
    "\n",
    "def search(img, windows, clf,scaler,hist_bins = 32, spatial_size = (16,16), hog_orientations = 9, hog_pixels_per_cell = (8, 8), hog_cells_per_block = (1, 1)):\n",
    "    result = []\n",
    "    #features = []\n",
    "    for window in windows:\n",
    "        img_small = img[window[0][1]:window[1][1], window[0][0]:window[1][0]]\n",
    "        if img_small.size:\n",
    "            img_small = cv2.resize(img_small, (64, 64))\n",
    "            img_small = cv2.cvtColor(img_small,cv2.COLOR_BGR2YCrCb)\n",
    "            \n",
    "            # extract color hist features\n",
    "            channel1 = np.histogram(img_small[:, :, 0],bins=hist_bins)\n",
    "            channel2 = np.histogram(img_small[:, :, 1],bins=hist_bins)\n",
    "            channel3 = np.histogram(img_small[:, :, 2],bins=hist_bins)\n",
    "            hist_feature = np.concatenate((channel1[0], channel2[0], channel3[0]))\n",
    "\n",
    "            # extract spatial features\n",
    "            spatial_features = cv2.resize(img_small,spatial_size).ravel()\n",
    "\n",
    "            # extract hog features\n",
    "            hog_feature = hog(img_small, orientations=hog_orientations, pixels_per_cell=hog_pixels_per_cell,\n",
    "                              cells_per_block=hog_cells_per_block, visualize=False,feature_vector=True)\n",
    "\n",
    "            \n",
    "            features = np.concatenate((hist_feature,spatial_features,hog_feature))\n",
    "    #             print(type(features),features.shape)\n",
    "    #             print(type(temp),temp.shape)\n",
    "    #             print(type(hist_feature),hist_feature.shape)\n",
    "            features = scaler.transform([features])\n",
    "            if clf.predict(features):\n",
    "                result.append(window)\n",
    "    return result\n",
    "\n",
    "def draw_windows(img,windows):\n",
    "    draw_img = np.copy(img)\n",
    "    for window in windows:\n",
    "        cv2.rectangle(draw_img, window[0],window[1], (0, 0, 255), 3)\n",
    "    return draw_img,windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "loving-contest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_data(train_path='./benchmark_velocity_train/clips/'):\n",
    "    train_dirs = os.listdir(train_path)\n",
    "    # Delete '.DS_Store' file in macOS system\n",
    "    train_dirs = [i for i in train_dirs if i != '.DS_Store']\n",
    "    clips_folders = list(map(int, train_dirs))\n",
    "    clips_folders.sort()\n",
    "\n",
    "    annotated_imgs = []\n",
    "    for i in clips_folders:\n",
    "        imgs_path = train_path + str(i) + '/imgs'\n",
    "        for _, _, imgs in os.walk(imgs_path):\n",
    "            imgs.sort()\n",
    "            for img_name in imgs:\n",
    "                img_path = imgs_path + '/' + img_name\n",
    "                if '040' in img_name:\n",
    "                    annotated_imgs.append(img_path)\n",
    "\n",
    "    annotations = [os.path.join(train_path, str(x), 'annotation.json') for x in clips_folders]\n",
    "    annotation_list = VeloEval.load_annotation(annotations)\n",
    "    car_imgs=[]\n",
    "    nocars=[]\n",
    "    img_count = 0\n",
    "    coordinates = []\n",
    "    for anno in tqdm(annotation_list):\n",
    "        top = int(anno[0]['bbox'][:, 0][0])\n",
    "        left = int(anno[0]['bbox'][:, 1][0])\n",
    "        bottom = int(anno[0]['bbox'][:, 2][0])\n",
    "        right = int(anno[0]['bbox'][:, 3][0])\n",
    "        coordinates.append([(top - 32,bottom + 32),(left - 32,right + 32)])\n",
    "        img = cv2.imread(annotated_imgs[img_count])\n",
    "        img_resized = cv2.resize(img[top:bottom, left:right], (64, 64), interpolation=cv2.INTER_CUBIC)\n",
    "        car_imgs.append(img_resized)\n",
    "        img_count += 1\n",
    "    return car_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "chemical-castle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_heat(heatmap, bbox_list):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in bbox_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "    return heatmap\n",
    "def apply_threshold(heatmap, threshold):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap\n",
    "def draw_labeled_bboxes(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "    # Return the image\n",
    "    plt.imshow(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "welsh-description",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from given source: TuSimple Competitions for CVPR2017 \n",
    "# https://github.com/TuSimple/tusimple-benchmark\n",
    "class VeloEval(object):\n",
    "    @staticmethod\n",
    "    def load_json_file(file_list):\n",
    "        data_list = []\n",
    "        for file_name in file_list:\n",
    "            with open(file_name) as f:\n",
    "                raw_data = json.load(f)\n",
    "            data_list.append(raw_data)\n",
    "        return data_list\n",
    "\n",
    "    @staticmethod\n",
    "    def transform_annotation(raw_data_list):\n",
    "        anno_list = []\n",
    "        for raw_data in raw_data_list:\n",
    "            data = []\n",
    "            for instance in raw_data:\n",
    "                instance[\"bbox\"] = np.array([[instance[\"bbox\"][\"top\"],\n",
    "                                              instance[\"bbox\"][\"left\"],\n",
    "                                              instance[\"bbox\"][\"bottom\"],\n",
    "                                              instance[\"bbox\"][\"right\"]]])\n",
    "                data.append(instance)\n",
    "            anno_list.append(data)\n",
    "        return anno_list\n",
    "\n",
    "    @staticmethod\n",
    "    def load_annotation(file_list):\n",
    "        raw_data_list = VeloEval.load_json_file(file_list)\n",
    "        anno_list = VeloEval.transform_annotation(raw_data_list)\n",
    "        print(\"Finished loading {0:d} annotations.\".format(len(anno_list)))\n",
    "        return anno_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "organic-destiny",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1074 [00:00<00:13, 78.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading 1074 annotations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1074/1074 [00:11<00:00, 92.89it/s]\n",
      "100%|██████████| 5067/5067 [01:03<00:00, 80.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30140 87327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_cars = read_train_data()\n",
    "img, cars, nocars = retrive_data(noncar_size=15)\n",
    "cars.extend(train_cars)\n",
    "#nocars.extend(train_nocars)\n",
    "print(len(cars),len(nocars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-prairie",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction parameters\n",
    "hist_bins = 32\n",
    "spatial_size = (16,16)\n",
    "hog_orientations = 9\n",
    "hog_pixels_per_cell = (8, 8)\n",
    "hog_cells_per_block = (1, 1)\n",
    "\n",
    "# extract features\n",
    "car_features = retrive_features(cars, hist_bins, spatial_size, hog_orientations, hog_pixels_per_cell, hog_cells_per_block)\n",
    "nocars_features = retrive_features(nocars,hist_bins, spatial_size, hog_orientations, hog_pixels_per_cell, hog_cells_per_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-calculation",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 1\n",
    "\n",
    "# train the features\n",
    "clf,scaler = train(car_features, nocars_features, random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-moldova",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_imgs, annotations = read_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-amplifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single image car detect\n",
    "overlap = 0.8\n",
    "window_size= (64, 64)\n",
    "single_sup_img = copy(img[14])\n",
    "single_train_img = cv2.imread(\"./benchmark_velocity_test/clips/7/imgs/040.jpg\")\n",
    "windows = search(single_train_img,slide_window(single_train_img, window_size,overlap),clf,scaler,hist_bins, spatial_size, hog_orientations, hog_pixels_per_cell, hog_cells_per_block)\n",
    "draw_img,windows = draw_windows(single_train_img,windows)\n",
    "plt.imshow(draw_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-insider",
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_map = np.zeros(single_train_img.shape[:2])\n",
    "heat_map = add_heat(heat_map,windows)\n",
    "heat_map_thresholded = apply_threshold(heat_map,1)\n",
    "labels = label(heat_map_thresholded)\n",
    "draw_img = draw_labeled_bboxes(single_train_img,labels)\n",
    "#plt.imshow(heat_map)\n",
    "print(labels)\n",
    "#plt.imshow(draw_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "combined-particle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f94ff7c40d0>"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(heat_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-commodity",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:COMP9517]",
   "language": "python",
   "name": "conda-env-COMP9517-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
